{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<div>\n","<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n","</div>"],"metadata":{"id":"x0wJ6ih0dGue"}},{"cell_type":"markdown","source":["# Lab 10.3 PySpark for Big Data"],"metadata":{"id":"q9ROjAGE3Xwe"}},{"cell_type":"markdown","source":["## Introduction\n","\n","**Note**: this notebook is to be run in Google Colab on your Google Drive. It will not work locally on your computer.\n","\n","The purpose of this lab is to gain further exposure to cloud computing, often necessary when datasets become too large to manage on a local machine. You will learn how to work with a large dataset through the PySpark Python library with Google Colaboratory (Colab).\n","\n","In Google Colab, a virtual machine is automatically set up to execute your code. The maximum lifetime of such a machine is 12 hours. Note that notebooks will be disconnected from virtual machines if left idle. If this happens simple click on the Connect button to reconnect. If the kernel needs to be restarted (via the Runtime menu), variables may be lost but packages would not need to be reinstalled unless a new machine is assigned. \n","\n","https://research.google.com/colaboratory/faq.html"],"metadata":{"id":"b1x0a8wS36Dg"}},{"cell_type":"markdown","source":["Sign into colab.research.google.com and choose the Upload tab and upload this notebook.  This will automatically create a folder called \"Colab Notebooks\" in your Google Drive (if it does not already exist)."],"metadata":{"id":"9Aofk5PAOjiy"}},{"cell_type":"markdown","source":["Apache Spark is an open-source cluster-computing framework, able to work with large datasets quickly by performing in-memory caching and computation. Pyspark is a Python API for Spark commonly used to manipulate big data. For reference one useful cheat sheet is available at https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf\n","\n","\n","Fortunately Pyspark is straightforward to setup in Google Colab:"],"metadata":{"id":"Q9D2nLzvpvXG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OjLwFBPiHjE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696313054,"user_tz":-780,"elapsed":36596,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"90cf2214-462b-4ca7-c707-69f6b1f44733"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting py4j\n","  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=2e8f6563d53286cbb649c7f3ecda60d4493496e019d101f79423aea191651be8\n","  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"]}],"source":["!pip install pyspark py4j"]},{"cell_type":"markdown","source":["To work with Spark DataFrames we firstly need to create a Spark DataFrame:"],"metadata":{"id":"AqVKUUfaPAFk"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, trim, avg, round, when\n","from pyspark import SparkFiles\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"EVkw1kauisG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"populationdata\").getOrCreate()"],"metadata":{"id":"0DhoqhUfjLLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"VR8Wz35Srk2e","executionInfo":{"status":"ok","timestamp":1678696324227,"user_tz":-780,"elapsed":2486,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"e1d76359-f123-48c0-868f-d72739091175"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f641f8427f0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://1415387a6f25:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>populationdata</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Loading the dataset and EDA"],"metadata":{"id":"fniWWP-mUHbj"}},{"cell_type":"markdown","source":["The dataset to be analysed in this lab shows population estimates by age and gender:\n","\n","   - PopMale: Male population for the individual age (thousands)\n","   - PopFemale: Female population for the individual age (thousands)\n","   - PopTotal: Total population for the individual age (thousands)\n","\n","Further details can be found at https://population.un.org/wpp/."],"metadata":{"id":"ARXXUB6T4YyX"}},{"cell_type":"code","source":["from google.colab import drive"],"metadata":{"id":"JY19NkC_Jqmz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"CaOdrG_WJqda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run this cell after uploading the file into your Colab Notebooks folder\n","df = spark.read.csv(r\"/content/drive/MyDrive/Colab Notebooks/WPP2019_PopulationBySingleAgeSex_1950-2019.csv\", header=True)"],"metadata":{"id":"W9PIO6ccj11y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(df)"],"metadata":{"id":"0HBFMsS4S_0y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337013,"user_tz":-780,"elapsed":17,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"3c46565d-591d-4157-8b81-067887736edc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df"],"metadata":{"id":"gjGaJckiP5Wq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337013,"user_tz":-780,"elapsed":10,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"75e760d7-2bac-4440-bfea-246f6867acbd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[<!DOCTYPE html>: string]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Note that unlike Pandas this does not display a preview of the dataset, only the schema. This is because Spark performs lazy evaluation, only displaying rows when needed."],"metadata":{"id":"jx2B5DdBt-uv"}},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"x2oftXQoXLM5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337014,"user_tz":-780,"elapsed":8,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"89894d43-cfb4-4220-89af-872f5f699935"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<!DOCTYPE html>']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["**Exercise**: How many rows does df contain?"],"metadata":{"id":"P0T1d7f8ucdV"}},{"cell_type":"code","source":["# ANSWER\n","df.count()"],"metadata":{"id":"Or9UO3KfkO2j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337510,"user_tz":-780,"elapsed":502,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"35803574-13d0-4c8e-b585-759c61b2e1cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1165"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["df.rdd.getNumPartitions()"],"metadata":{"id":"3OrPKvO1wwmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337834,"user_tz":-780,"elapsed":327,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"6746189f-790c-4908-cfcc-a8f1f55bcd29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["This corresponds to the number of cores in a free Google Colab instance."],"metadata":{"id":"laKXx1YuVHzJ"}},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"id":"U46UOmCm-JGW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337834,"user_tz":-780,"elapsed":8,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"f5933075-c8c1-4159-9700-51484d3f422b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- <!DOCTYPE html>: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["We use df.show() similarly to df.head() in Pandas."],"metadata":{"id":"Wbu-qsbAurU_"}},{"cell_type":"code","source":["df.show()"],"metadata":{"id":"2gErdsL3kcMu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696337835,"user_tz":-780,"elapsed":6,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"b465eaff-d6f4-4ca7-9f7a-8fc84e03fb41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|     <!DOCTYPE html>|\n","+--------------------+\n","|<html xmlns=\"http...|\n","|<head><meta chars...|\n","|    <style type=\"...|\n","|        /* Styles...|\n","|              body {|\n","|            font-...|\n","|            font-...|\n","|            line-...|\n","|                   }|\n","|                  h1|\n","|            font-...|\n","|            font-...|\n","|            line-...|\n","|            color...|\n","|                   }|\n","|                  h1|\n","|            margi...|\n","|            margi...|\n","|                   }|\n","|                  h1|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["df.describe()"],"metadata":{"id":"yzxQaJivXU-d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696339201,"user_tz":-780,"elapsed":1369,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"459c1282-7e8f-4eea-f33f-3a2d92946c7e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[summary: string, <!DOCTYPE html>: string]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Once again evaluation of describe is lazy, we use show() to display results:"],"metadata":{"id":"SRiwEStKu1Bj"}},{"cell_type":"markdown","source":[],"metadata":{"id":"b086yRpkcFm1"}},{"cell_type":"code","source":["df.describe().show()"],"metadata":{"id":"019DYlC1Xa4f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696339761,"user_tz":-780,"elapsed":564,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"c88ee0db-1b00-4a1c-b85d-86c956eb92a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+--------------------+\n","|summary|     <!DOCTYPE html>|\n","+-------+--------------------+\n","|  count|                1165|\n","|   mean|                null|\n","| stddev|                null|\n","|    min|         \\t\\t\\t</ul>|\n","|    max|function prepareO...|\n","+-------+--------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Let us remove rows we do not need."],"metadata":{"id":"cUaRjQT1UKQA"}},{"cell_type":"code","source":["df.select('VarID', 'Variant').distinct().show()"],"metadata":{"id":"NGE3jFrNnKPN","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"error","timestamp":1678696339761,"user_tz":-780,"elapsed":11,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"551cf710-6040-4fa5-ff3d-77e2974ae1f1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-bc48cbb3f3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VarID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Column 'VarID' does not exist. Did you mean one of the following? [<!DOCTYPE html>];\n'Project ['VarID, 'Variant]\n+- Relation [<!DOCTYPE html>#17] csv\n"]}]},{"cell_type":"markdown","source":["As we will not work with other variant, we can safely drop these columns."],"metadata":{"id":"ImP40Am2Ubyk"}},{"cell_type":"code","source":["df = df.drop('VarID', 'Variant')"],"metadata":{"id":"FcUa1NXkUvuK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.show()"],"metadata":{"id":"E9JqgSV8U0MO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696385681,"user_tz":-780,"elapsed":7,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"425f8844-b16e-4d8b-f0f4-1fb5230fe1b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+\n","|     <!DOCTYPE html>|\n","+--------------------+\n","|<html xmlns=\"http...|\n","|<head><meta chars...|\n","|    <style type=\"...|\n","|        /* Styles...|\n","|              body {|\n","|            font-...|\n","|            font-...|\n","|            line-...|\n","|                   }|\n","|                  h1|\n","|            font-...|\n","|            font-...|\n","|            line-...|\n","|            color...|\n","|                   }|\n","|                  h1|\n","|            margi...|\n","|            margi...|\n","|                   }|\n","|                  h1|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["df.select('Location').distinct().count()"],"metadata":{"id":"FetISlkDkfte","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"error","timestamp":1678696389881,"user_tz":-780,"elapsed":6,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"8cdac31b-ee97-4116-e965-31a44e06afd0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-06e8c8ddf54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Column 'Location' does not exist. Did you mean one of the following? [<!DOCTYPE html>];\n'Project ['Location]\n+- Relation [<!DOCTYPE html>#17] csv\n"]}]},{"cell_type":"code","source":["df.select('Location').distinct().show()"],"metadata":{"id":"RLp0s2DNm_9J","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"error","timestamp":1678696407266,"user_tz":-780,"elapsed":966,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"83fb812c-6251-48c7-f379-f865cc5991b1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-c07cb1b786d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Column 'Location' does not exist. Did you mean one of the following? [<!DOCTYPE html>];\n'Project ['Location]\n+- Relation [<!DOCTYPE html>#17] csv\n"]}]},{"cell_type":"markdown","source":["**Exercise**: Repeat the above query, this time ordering the results by Location and using the truncate=False option to display results in full. Show all 440 results."],"metadata":{"id":"wGId26gpvIhA"}},{"cell_type":"code","source":["# ANSWER\n","df.select('Location').distinct().orderBy('Location').show(440, truncate=False)"],"metadata":{"id":"6n-RKO9GQ9d7","colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"status":"error","timestamp":1678696414460,"user_tz":-780,"elapsed":306,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"b6689720-e25f-452c-b301-b3cdb2fad0bb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-2c7583f1f65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ANSWER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m440\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Column 'Location' does not exist. Did you mean one of the following? [<!DOCTYPE html>];\n'Project ['Location]\n+- Relation [<!DOCTYPE html>#17] csv\n"]}]},{"cell_type":"markdown","source":["Next run the following to confirm that there are no missing values in this dataset:"],"metadata":{"id":"4yDHFBOxvoAu"}},{"cell_type":"code","source":["df.count() - df.na.drop().count()"],"metadata":{"id":"ED5mlcDZWQ_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678696457763,"user_tz":-780,"elapsed":758,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"ba0ac9fc-c518-4667-9741-2ab42584c79c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Convert types"],"metadata":{"id":"vM0ibqHheNwi"}},{"cell_type":"markdown","source":["We saw above that all columns are in the form of strings. The following cell converts some of the columns to type float."],"metadata":{"id":"tp9mGREhvt9b"}},{"cell_type":"code","source":["floatcols = ['MidPeriod', 'PopMale', 'PopFemale', 'PopTotal']\n","\n","for col_name in floatcols:\n","    df = df.withColumn(col_name, trim(col(col_name)).cast('float'))"],"metadata":{"id":"AhMt9KiAAQWm","colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"status":"error","timestamp":1678696460712,"user_tz":-780,"elapsed":640,"user":{"displayName":"Muru Raj","userId":"16263509272652930332"}},"outputId":"9be467ef-2678-464d-9606-13a05d10ccd9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-3d7cc60f0669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfloatcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Column 'MidPeriod' does not exist. Did you mean one of the following? [<!DOCTYPE html>];\n'Project [<!DOCTYPE html>#17, cast(trim('MidPeriod, None) as float) AS MidPeriod#213]\n+- Relation [<!DOCTYPE html>#17] csv\n"]}]},{"cell_type":"markdown","source":["**Exercise**: Similarly convert the four columns listed below into **integers**. "],"metadata":{"id":"K3rr3rErWiLZ"}},{"cell_type":"code","source":["intcols = ['Time', 'AgeGrp', 'AgeGrpStart', 'AgeGrpSpan']\n","\n","#ANSWER\n","for col_name in intcols:\n","    df = df.withColumn(col_name, trim(col(col_name)).cast('int'))"],"metadata":{"id":"ccgnri3hJgk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"id":"O6S0JbDWDJM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Answering some queries about the data\n","\n","We use filter to select a subset of rows satifying a True/False condition:"],"metadata":{"id":"Y_A8nwmrlFQH"}},{"cell_type":"markdown","source":["Example: What was the population breakdown by age and gender in Australia in 1970?"],"metadata":{"id":"NPrXmt9ZlPjH"}},{"cell_type":"code","source":["df.filter((df.Location == 'Australia') & (df.Time == 1970)).show(101)"],"metadata":{"id":"JkwtyIjbeAR2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The select function can select a subset of columns.\n","\n","**Exercise**: What was the population of 45-year-old females in India in 1960?"],"metadata":{"id":"utx53EQwjUSY"}},{"cell_type":"code","source":["# ANSWER\n","df.filter((df.AgeGrp == 45)\\\n","          & (df.Location == 'India')\\\n","          & (df.Time == 1960))\\\n","          .select('PopFemale')\\\n","          .show()"],"metadata":{"id":"zwxYNG2qjpft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise**: Write a filter query to show the distinct locations starting with 'UN'."],"metadata":{"id":"13IpzCh23AdD"}},{"cell_type":"code","source":["# ANSWER\n","\n","df.filter(df.Location.startswith('UN'))\\\n","  .select('Location')\\\n","  .distinct()\\\n","  .show(40, truncate=False)"],"metadata":{"id":"dmgSw_z7s_-S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Another example: what is the population of each location in 1950 and 2019?"],"metadata":{"id":"Ucwk6vQ0qu63"}},{"cell_type":"code","source":["populations_in_1950 = df.filter(df.Time == 1950)\\\n","                    .groupBy('Location')\\\n","                    .sum('PopTotal')\\\n","                    .withColumnRenamed('sum(PopTotal)', 'Population_1950')\\\n","                    .withColumn('Population_1950', round('Population_1950', 3))\\\n","                    .orderBy(col('Population_1950').desc())\n","populations_in_1950.show()"],"metadata":{"id":"C_L9r2lLq1ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["populations_in_2019 = df.filter(df.Time == 2019)\\\n","                    .groupBy('Location')\\\n","                    .sum('PopTotal')\\\n","                    .withColumnRenamed('sum(PopTotal)', 'Population_2019')\\\n","                    .withColumn('Population_2019', round('Population_2019', 3))\\\n","                    .orderBy(col('Population_2019').desc())\n","          "],"metadata":{"id":"DT125gNwiBn-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["populations_in_1950.join(populations_in_2019, 'Location').orderBy('Location').show()   "],"metadata":{"id":"TGQ3PPvDiWu3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise**: Which locations had the largest percentage change in population from 1950 to 2019?"],"metadata":{"id":"XUmwRcHuXxVo"}},{"cell_type":"code","source":["# ANSWER\n","populations_in_1950\\\n","  .join(populations_in_2019, 'Location')\\\n","  .orderBy('Location')\\\n","  .withColumn('Percentage_change', \n","              round(100*populations_in_2019.Population_2019\\\n","              /populations_in_1950.Population_1950, 2))\\\n","  .orderBy(col('Percentage_change').desc())\\\n","  .show(truncate=False)"],"metadata":{"id":"gZWfatPCl4vu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bonus Exercise**: In 2019 which locations have the highest percentage of seniors (age 80+) relative to their total population? \n","\n","(Hint: if you find Japan, Greece and Italy you are right!)"],"metadata":{"id":"Amz7aJ8TpWju"}},{"cell_type":"code","source":["# ANSWER\n","seniors_2019 = df.filter((df.Time == 2019) & (df.AgeGrp >= 80))\\\n","                  .groupBy('Location')\\\n","                  .sum('PopTotal')\\\n","                  .withColumnRenamed('sum(PopTotal)', 'Senior_Population_2019')\\\n","                  .withColumn('Senior_Population_2019',\\\n","                              round('Senior_Population_2019', 3))\\\n","                  .orderBy(col('Senior_Population_2019').desc())\n","\n","populations_in_2019\\\n","  .join(seniors_2019, 'Location')\\\n","  .withColumn('Percentage_of_Seniors', \n","              round(100*seniors_2019.Senior_Population_2019\\\n","              / populations_in_2019.Population_2019, 2))\\\n","  .orderBy(col('Percentage_of_Seniors').desc())\\\n","  .show(truncate=False)"],"metadata":{"id":"j9aqlueYo2x1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Population line plot\n","\n","In this section, we use a query to perform a data visualisation with matplotlib. We shall plot population vs year for three countries."],"metadata":{"id":"JF2elDeHXRpY"}},{"cell_type":"code","source":["df_3countries = df[df.Location.isin(\"Australia\", \"New Zealand\", \"Singapore\")]\\\n","                  .select('Location', 'MidPeriod', 'PopTotal') \\\n","                  .groupBy('Location', 'MidPeriod')\\\n","                  .sum('PopTotal')\\\n","                  .withColumnRenamed('sum(PopTotal)', 'Population')\\\n","                  .withColumn('Population', round('Population', 3))\n","df_3countries.show()"],"metadata":{"id":"on49bDYynXuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataforplotting = df_3countries.toPandas()"],"metadata":{"id":"94YAOx4DggYX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that this dataset is of a manageable size, we convert it to a Pandas dataframe for plotting."],"metadata":{"id":"HizTgSBkYP80"}},{"cell_type":"code","source":["dataforplotting.info()"],"metadata":{"id":"MTcUn1rWZw3H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataforplotting.pivot_table(index=['MidPeriod'], columns='Location', values='Population')"],"metadata":{"id":"QkkQaikca5ic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ax = dataforplotting.pivot_table(index=['MidPeriod'], columns='Location', values='Population').plot()\n","ax.set_xlabel('Year');\n","ax.set_ylabel('Population in thousands');"],"metadata":{"id":"4Su9Q_zRYafh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bonus Exercise**: Plot the world population of children (age 0-17) along with those of the age groups 18-39 and 40+ from 1950 to 2019. You should display three lines (one for the population of each age group vs year) on the same plot. Note that 'World' is one of the locations. \n","\n","Hint: one approach is to create a new column 'AgeCategory' based on AgeGrpStart using the 'when' function."],"metadata":{"id":"lk7vpgzhoyyu"}},{"cell_type":"code","source":["# ANSWER\n","world_data = df[df.Location == \"World\"]\\\n","                  .withColumn('AgeCategory',\\\n","                              when(df.AgeGrpStart <= 17, '0-17')\\\n","                              .when(df.AgeGrpStart >= 40, '40+')\\\n","                              .otherwise('18-39'))\\\n","                  .select('MidPeriod', 'AgeGrpStart',\\\n","                          'AgeCategory', 'PopTotal') \\\n","                  .groupBy('MidPeriod', 'AgeCategory')\\\n","                  .sum('PopTotal')\\\n","                  .withColumnRenamed('sum(PopTotal)', 'Population')\\\n","                  .withColumn('Population', round('Population', 3))"],"metadata":{"id":"3seZfEDKztf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agegrp_df = world_data.toPandas()"],"metadata":{"id":"r4TBvqSxNB0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ax = agegrp_df.pivot_table(index=['MidPeriod'], columns='AgeCategory', values='Population').plot()\n","ax.set_xlabel('Year');\n","ax.set_ylabel('Population in thousands');"],"metadata":{"id":"zvn4652v0LBB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Population Pyramid\n","\n","In this section we show how a population pyramid may be created. We look at China in the year 1980."],"metadata":{"id":"CjanSfzLshCY"}},{"cell_type":"code","source":["china_1980 = df.filter((df.Location == 'China (and dependencies)') & (df.Time == 1980)).toPandas()"],"metadata":{"id":"y-kPKZoSpvu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["china_1980"],"metadata":{"id":"7QO-QPj5-BFa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["china_1980.describe()"],"metadata":{"id":"nDnOzJv590KU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create age brackets in multiples of 5 - such as 0-4, 5-9, ..."],"metadata":{"id":"sxwmLmbpT-MU"}},{"cell_type":"code","source":["lower = china_1980['AgeGrpStart'] - (china_1980['AgeGrpStart'] % 5)"],"metadata":{"id":"EDNkxHWPtIBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agebrackets = [f'{x:02d}-{(x+4):02d}' for x in lower.values]\n","agebrackets[-1] = '100+'"],"metadata":{"id":"qDdobQzVvS6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agebrackets[:10]"],"metadata":{"id":"aXkHlTwrUJgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["china_1980['AgeRange'] = agebrackets"],"metadata":{"id":"zLRoES0Lv-DV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next find the populations by age range."],"metadata":{"id":"wFh9qf_QUYmA"}},{"cell_type":"code","source":["agg_china_1980 = (china_1980.groupby(['AgeRange']).sum()[['PopMale', 'PopFemale']]/1000).reset_index()"],"metadata":{"id":"HzwkqTnfvIbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rev_age = list(dict.fromkeys(agebrackets[::-1])) #reversed list of ages"],"metadata":{"id":"LZ56Ouu0xshz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agg_china_1980['NegPopMale'] = -agg_china_1980['PopMale']"],"metadata":{"id":"Rr81_Qa03L49"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are now ready to plot the population pyramid:"],"metadata":{"id":"BO-L2tVTUzMv"}},{"cell_type":"code","source":["sns.set(rc={'figure.figsize':(12,8)})\n","bar_plot = sns.barplot(x='NegPopMale', y='AgeRange', data=agg_china_1980, order = rev_age, color='red')\n","bar_plot = sns.barplot(x='PopFemale', y='AgeRange', data=agg_china_1980, order = rev_age, color='green')\n","\n","labels = [\"80\", \"60\", \"40\", \"20\", \"0\", \"20\", \"40\", \"60\", \"80\"]\n","bar_plot.set_xticklabels(labels)\n","\n","h = [bar_plot.bar(x=.1, height=.1, color = c) for c in ['red', 'green']] #used to set colour of bar in legend\n","bar_plot.legend(handles = h, labels=['Male', 'Female'], fontsize=20)\n","\n","bar_plot.axes.set_title(\"Population Pyramid for China (1980)\", fontsize=20);\n","bar_plot.set_xlabel(\"Population (millions)\", fontsize=20);\n","bar_plot.set_ylabel(\"Age Group\", fontsize=20);\n","bar_plot.set_xticklabels(bar_plot.get_xticklabels(), size = 15);\n","bar_plot.set_yticklabels(bar_plot.get_yticklabels(), size = 15);"],"metadata":{"id":"PH5G2AS2GM5P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prediction\n","Finally we use Spark's MLlib library in a linear regression problem. We shall predict the proportion of population to be of a particular age, given year.\n","\n","Inputs:\n","- year\n","- age\n","\n","Target variable: \n","- proportion of a country's population to be of that age, in that year\n"],"metadata":{"id":"pco3DxAAAo_b"}},{"cell_type":"code","source":["pop_by_loc_and_year = df.groupBy('Location', 'Time')\\\n","                        .sum('PopTotal')\\\n","                        .withColumnRenamed('sum(PopTotal)', 'Location_year_pop')"],"metadata":{"id":"3mB-EMYcA98W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pop_by_loc_and_year.show()"],"metadata":{"id":"SxNyiVNEPxsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainingset = df.join(pop_by_loc_and_year, ['Location', 'Time'])\\\n","  .withColumn('Proportion', \n","              df.PopTotal/pop_by_loc_and_year.Location_year_pop)\\\n","  .select('Time', 'AgeGrpStart', 'Proportion')"],"metadata":{"id":"B_77KVAtFLeL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise**: Use the stat.corr function to find the correlation between AgeGrpStart and Proportion."],"metadata":{"id":"UHP4f5U0VtVX"}},{"cell_type":"code","source":["# ANSWER\n","trainingset.stat.corr(\"AgeGrpStart\", \"Proportion\") #strong negative correlation"],"metadata":{"id":"rIB8svOhRJo7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we create a simple linear regression model predict Ratio from Time and AgeGrpStart."],"metadata":{"id":"FGzfs8RvRvta"}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression"],"metadata":{"id":"wLtarw5JRuSX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MLlib takes input in vector form. Hence we need to create vectors from features."],"metadata":{"id":"S23U0wGtS4jg"}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n","featureassembler=VectorAssembler(inputCols=['Time', 'AgeGrpStart'],\n","                                 outputCol='Features')"],"metadata":{"id":"IJH5U9jXSFvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_data_for_regression = featureassembler.transform(trainingset).select('Features', 'Proportion')\n","final_data_for_regression.show()"],"metadata":{"id":"LVFE_bD2TjQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train, test = final_data_for_regression.randomSplit([0.9,0.1])"],"metadata":{"id":"JdJMPuEaUsU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"id":"j0g2C3q7WJcn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we cache these dataframes into memory:"],"metadata":{"id":"MDQKO1uSWbRk"}},{"cell_type":"code","source":["train = train.cache()"],"metadata":{"id":"RMlSH4bSawox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = test.cache()"],"metadata":{"id":"DQA6_pKbcRil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are ready to train the model. This may take a minute or so due to the size of training set."],"metadata":{"id":"5tCkn1JRWkp_"}},{"cell_type":"code","source":["regressor = LinearRegression(featuresCol='Features', labelCol='Proportion')\n","regressor = regressor.fit(train)"],"metadata":{"id":"HENx9aRyT6ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor.coefficients"],"metadata":{"id":"cB1xBOeBUtq0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor.intercept"],"metadata":{"id":"cuq7d9GRUzjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_results = regressor.evaluate(test)"],"metadata":{"id":"r1hn6SdxU0rR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we can compare some predicted proportions with actual proportions:"],"metadata":{"id":"LOoUldddbOCu"}},{"cell_type":"code","source":["predicted_results.predictions.show()"],"metadata":{"id":"B5oY-pWtVI0t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercise**: Find R-squared and the mean squared error using the 'r2' and 'meanSquaredError' attributes."],"metadata":{"id":"qnFtxazpW65a"}},{"cell_type":"code","source":["# ANSWER\n","predicted_results.r2, predicted_results.meanSquaredError"],"metadata":{"id":"CiExfxhOcwmx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Conclusion\n","\n","We have seen how to use Pyspark to make queries on a large dataset, save smaller datasets into Pandas dataframe for plotting and how to use MLlib for machine learning on a large dataset. "],"metadata":{"id":"WLEy2Q5R0sUP"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","> > > > > > > > > © 2023 Institute of Data\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"-Rws5UYfXrSZ"}}]}