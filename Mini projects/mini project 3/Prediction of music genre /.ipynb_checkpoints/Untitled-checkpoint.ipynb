{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f8aa11-057e-4c9a-b1f1-a80aed24c744",
   "metadata": {},
   "source": [
    "Comprehensive EDA, class consolidation and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960b01fd-cdaf-4063-acd2-5d8c6aa04c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.stats import zscore\n",
    "import fasttext\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a200e46-ab92-4a50-b2fa-2580193f1c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5dd5cf-060d-48ef-8d17-47150abde47a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0dc1bb4-521f-4844-95a7-30a8dec386c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673403bd-35b0-4117-9691-9a60ef7837fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cb0bba-9141-439a-9909-b88951c6b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0a26ad-9cf6-44d0-865d-231e56e8d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb458f8-2bc0-4656-b08d-32650f00c406",
   "metadata": {},
   "source": [
    "We can see that there are 17 features and one label column (music_genre). Out of the features, 12 are numerical (one of which, tempo, is missclassified and will be dealt with later), and 5 are categorical.\n",
    "We can also already see hints to hidden missing values in 3 features ('tempo', 'artist_name' and 'duration_ms'). Those will be dealt with shortly one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5554add-b376-41b0-bb4e-3cce76e81b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the data is balanced\n",
    "data['music_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6e7f7-7195-4bdf-bdc0-8a636701940b",
   "metadata": {},
   "source": [
    "\n",
    "There are 10 different genres with equal distribution (balanced data). This means the accuracy score will be a good metric to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a46ac-080f-4870-84c7-09c9147f99f6",
   "metadata": {},
   "source": [
    "\n",
    "Exploring the features one by one:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548eba25-0424-45f6-aab3-3197bd29ab90",
   "metadata": {},
   "source": [
    "\n",
    "Instance_id:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8924d8f1-643f-4326-925d-3e8f1b4b1593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['instance_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87abda66-0ccd-4abc-b96e-b09f72ac16be",
   "metadata": {},
   "source": [
    "\n",
    "Artist's Names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab62bc6-75e7-48bb-a572-0404785e45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"There are {data['artist_name'].nunique()} unique artists in the set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10156419-3a21-4a4b-bfce-8b25fa59a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['artist_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb94468-2084-4fce-a86a-2211e6115450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "missing_artist = data[data['artist_name'] == 'empty_field']\n",
    "missing_artist.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d586b5ce-45fc-423f-88f7-8cec661a8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"Percent of missing artist names: {(missing_artist.shape[0]/data.shape[0])*100:2.4}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50085bec-0bfe-47c5-a2e8-bf9834b101fb",
   "metadata": {},
   "source": [
    "\n",
    "5% of the observations are missing the artist's names (marked as 'empty_field'), but these entries are still valid otherwise. we will not drop these observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ca70be-3617-4ed5-824c-8be8bf5f95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data[data['artist_name'] != 'empty_field'].groupby('artist_name')['music_genre'].nunique().value_counts(normalize=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a292ed0-a5f9-460e-9d28-04b9923bcc3f",
   "metadata": {},
   "source": [
    "For the entries that do contain an artist's name, it seems that a song that comes from a particular artist has an ~80% chance of belonging to one specific genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f9a7e-5093-4c06-ac20-57733586ac2c",
   "metadata": {},
   "source": [
    "However, in it's current form it's not helpful for classifying songs from artists outside the training set. We'll need to extract more general features, starting with the simplest - name length.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff991cc-25a3-4db8-b33a-b959f0b16e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find the length of the artists names\n",
    "data['length_name'] = data['artist_name'].str.len()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a5407f-db21-4692-aa63-24e9fd1c279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data[data['artist_name'] != 'empty_field'].groupby('music_genre')['length_name'].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d2d7f1-a2d7-41b1-84ca-213acf2f83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = data['music_genre'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "genre_counts.plot.pie(autopct='%.1f%%', startangle=90)\n",
    "plt.title(\"Music Genre Distribution\")\n",
    "plt.ylabel('')  # Remove the y-axis label ('genre')\n",
    "\n",
    "# Save the pie chart to a file\n",
    "plt.savefig('music_genre_distribution.png', bbox_inches='tight')\n",
    "\n",
    "# Show the pie chart (optional, since it's already saved)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c1c35-7801-447b-a279-d7c54180a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968301ba-d454-4ed0-ae92-be9061150e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data[data['artist_name'] != 'empty_field'], x='music_genre', y='length_name')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2ce9b-b037-4001-9b0a-3f667bb344b1",
   "metadata": {},
   "source": [
    "\n",
    "From the above statistics it seems that classical music tends to have noticeably longer names. Could potentialy be a useful feature. We'll keep it in for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d254e0e-090c-4760-ae29-b0dcf32b4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['track_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89106889-f085-47ee-b252-f51682a60304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate track name length\n",
    "data['length_track_name'] = data['track_name'].str.len()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f2b45-74b4-45a0-b285-5222f449dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.groupby('music_genre')['length_track_name'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b33603-1644-43f5-8bdc-2321d4c85ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='length_track_name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745318dd-73b0-4565-8e2c-84b0fb808337",
   "metadata": {},
   "source": [
    "The classical genre also has longer track names. The difference is much more pronounced than for the artist's name. This is a better feature for us to use, since it doesn't have the missing values problem. We'll use this and not the artist name length feature.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5b844-3195-42a2-a691-880827c500c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# drop 'length_name' feature\n",
    "data = data.drop(columns = ['length_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616aeb8-3bd2-40e5-a62b-a56d47f75a31",
   "metadata": {},
   "source": [
    "\n",
    "Next we'll make a feature out off the sample's language. Specifically, whether it's written in Japanese. This may help us identify the Anime genre, which is likely to contain track/artist names written in the Japanese alphabet, as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92ae50-b97d-4f9a-95cb-6f6815432a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pretrained language identification model\n",
    "os.system(f\"wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5f0ff-b6ff-4bda-a8b7-0433483adbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['music_genre'] == 'Anime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67102d-71be-47b0-bff8-5aca15be190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = 'lid.176.ftz'\n",
    "model = fasttext.load_model(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b0700-dc0d-4ce6-b3af-b326c1282d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_japanese(df):\n",
    "    '''\n",
    "    returns a 1D-array of 0's ans 1's, as well as the confidence of each prediction.\n",
    "    1 - if either the artist or track name is written in japanese.\n",
    "    0 - otherwise\n",
    "    ''' \n",
    "    jap = []\n",
    "    confidence = []\n",
    "    \n",
    "    for _, row in df.iterrows():      \n",
    "        pred_track, confidence_track = model.predict(row['track_name'])\n",
    "        pred_track = pred_track[0].split('__')[-1]\n",
    "        pred_artist, confidence_artist = model.predict(row['artist_name'])\n",
    "        pred_artist = pred_artist[0].split('__')[-1]\n",
    "\n",
    "        # check the confidence of the language detection\n",
    "        if (pred_track == 'ja') or (pred_artist == 'ja'):\n",
    "            jap.append(1)\n",
    "            confidence.append(np.max([confidence_track[0], confidence_artist[0]]))\n",
    "        else:\n",
    "            jap.append(0)\n",
    "    \n",
    "    return jap, np.array(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dca056-9982-4a08-ba79-3f5382fec1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Japanese'], confidence = find_japanese(data[['artist_name', 'track_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dd40a-d9b8-4062-adeb-f39468ff7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average confidence level for the japanese predictions is {confidence.mean():1.2} +\\- {confidence.std():1.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ac0fa-fb35-4f34-b34e-d923b6dcf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.groupby('music_genre')['Japanese'].value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142062d-f01f-403d-a0cd-3524bb0d08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jap = data.groupby('music_genre')['Japanese'].value_counts(normalize=True)\n",
    "jap = jap.unstack()\n",
    "jap.plot(kind='bar', stacked=True)\n",
    "\n",
    "plt.xlabel('Music Genre')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Japanese Songs by Music Genre')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9f090-e6eb-4797-9c2e-cf586881e9c4",
   "metadata": {},
   "source": [
    "More than 20% of the Anime tracks are indeed written in Japanese, a much higher percentage than all the other music genres combined. This could indeed help us identify the Anime genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938671e3-6fdf-438f-b0a6-d8da9ee9ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = data.drop(columns=['artist_name', 'track_name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23765eca-7583-43d3-9892-ced9806bbaec",
   "metadata": {},
   "source": [
    "Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefc4f4-5292-4a7c-b451-09213757b1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb77b35-1386-448e-8f2a-89b0671176df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589362a4-f45a-4285-81a6-75318bffb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='popularity')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad741b-c7c0-4d9a-a665-887c146f9dc2",
   "metadata": {},
   "source": [
    "This feature shows a nice spread of distributions for the different genres. Could definitely be useful for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66a899-21db-46d9-91c7-9c14739ec3c5",
   "metadata": {},
   "source": [
    "Rap, Hip-Hop and Rock seem to be the most popular genres, while Anime, Blues and Classical are the least popular. The other 4 genres are somewhere in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f4d22-e2a1-4ae4-9096-5ebf472675ad",
   "metadata": {},
   "source": [
    "Acousticness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23270036-181f-4af3-8cd6-4b67a9b48d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['acousticness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d517a9-a873-4e37-9de4-89eb971b947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='acousticness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b6812-74e9-4949-88a1-99e0ba1c4393",
   "metadata": {},
   "source": [
    "Danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105af45d-2609-475e-ba94-cd6f6c550246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['danceability'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fc698-c997-461c-9964-4ad467f8be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='danceability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f81849-979b-4212-9e86-b16c381da18c",
   "metadata": {},
   "source": [
    "\n",
    "Classical music sticks out again, but Rap and Hip-Hop can also be distinguished from the rest (they seem to go together often).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f07cc2-9bd4-4131-82f4-5912c75535f0",
   "metadata": {},
   "source": [
    "Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f53da2-b918-422e-a5fa-e545c5e20096",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['duration_ms'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916206d0-4bc6-48d3-97a5-3e2f6636e868",
   "metadata": {},
   "source": [
    "\n",
    "-1.0 is obvously not a valid time measurement. These are missing values.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae5dcb-02de-41c3-8aa6-1c6157a9197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_duration = data[data['duration_ms'] == -1].shape[0]\n",
    "num_obs_tot = data.shape[0]\n",
    "print(f\"There are {miss_duration} missing values, which accounts for {(miss_duration/num_obs_tot)*100:2.4}% of the data points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62c45f-9d38-4980-bd99-f98568e4695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data[data['duration_ms'] != -1], x='music_genre', y='duration_ms')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a494f05-92d9-4065-8833-301a315de415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c777706-26d2-468d-afa3-efd8843d8ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d23ef7-c4e2-4716-9c30-ac31cdf153ba",
   "metadata": {},
   "source": [
    "Almost 10% of the entries are missing a duration. We don't want to remove such a large amount of observations, so we'll fill in the missing values with the median, but consider removing the feature entirely in the future.\n",
    "Also of note is the fact that this feature contains extreme outliers. They could be important for classification, but we'll consider removing them at a later stage¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d14a7-6298-4f7d-9250-89af9e87c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fill in median for missing values\n",
    "mask_duration = data['duration_ms'] != -1\n",
    "median_duration = data.loc[mask_duration, 'duration_ms'].median()\n",
    "data.loc[~mask_duration, 'duration_ms'] = median_duration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e859e1-3182-4d08-9cec-d0be1ac4e63c",
   "metadata": {},
   "source": [
    "Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc3bd5-2b3f-4ca7-bb0d-5aadb4f901a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['energy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561642a2-f07d-4453-b2e8-1fdf0c63a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='energy')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e0ee1-587c-4f09-8a9a-b00d9600ad55",
   "metadata": {},
   "source": [
    "\n",
    "As usual, classical music stands out (and Jazz to a much lesser degree). Rap and Hip-Hop still match each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472bab9a-3eaf-4ba1-b78f-4a69c9500cd0",
   "metadata": {},
   "source": [
    "Instrumentalness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a403d-0230-4cd0-917a-e096f5b398be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.groupby('music_genre')['instrumentalness'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f58eff-cfc8-48b4-ad3d-ef7b90ec8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='instrumentalness')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d52763-cb5f-46ad-9488-7ec9390b932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='instrumentalness',data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495610a-cac0-4058-a129-e0cbf5b2c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_0 = data[data['instrumentalness'] == 0].shape[0]\n",
    "num_obs = data.shape[0]\n",
    "print(f\"There are {inst_0} observations with 0.0 instrumentalness, which accounts for {(inst_0/num_obs)*100:2.4}% of the data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c717f1-7591-4435-94c1-f7e0c3be9a2b",
   "metadata": {},
   "source": [
    "Such a large number of 0.0 entries likely indicates missing values rather than real data points. Since this is a 3rd of our observations, we won't fill in missing values. Instead, we'll discard this feature entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fa214-aa89-4e63-a14f-baaa7754905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['instrumentalness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29d8f1-3d07-4c7b-becb-871f1ba6e197",
   "metadata": {},
   "source": [
    "Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f8c1a-fbbd-4ddb-ab05-3294813beef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db9aa4-78ff-40aa-a01f-d308eb91d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"music_genre\", hue=\"key\",data=data, kind=\"count\",height=5, aspect=3.0, palette = 'Set1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008ba1-4f76-4d81-bfe4-903edaefbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['key'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b91f5-b7de-45c3-b3d8-6989e586f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# One Hot Encoding\n",
    "data = pd.get_dummies(data, drop_first=True, prefix='key', columns=['key'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ecf76-9304-4ba7-bac6-2ea77b7a4fd6",
   "metadata": {},
   "source": [
    "\n",
    "Different genres have noticeably different spreads. We'll keep this feature, but use One Hot Encoding to make it useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878ff6f-20e8-4ad6-8603-e6bd99742754",
   "metadata": {},
   "source": [
    "Liveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1f51c-ef43-44aa-a930-3b3cd9d8c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['liveness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ade214-08b4-4835-8a0c-1492f11321dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='liveness')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd9e51-17d9-418e-8fda-e474c5ca07e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['liveness'].plot.kde()\n",
    "plt.legend()\n",
    "plt.xlim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbef8a9-653c-410e-a319-ee8ba81041ea",
   "metadata": {},
   "source": [
    "\n",
    "The distributions seem similarly skewed for all genres, so this feature will likely not contribute much to the model. We'll try both with and without this feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7cddc-95f9-401d-a0dd-fad88db52b74",
   "metadata": {},
   "source": [
    "Loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9ea99-8bdd-48ef-9be8-ad9c851a38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['loudness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a8d00-7a5f-4fd7-ab00-11bb21cb7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='loudness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991e690-fd03-4c86-8dee-234111ec257c",
   "metadata": {},
   "source": [
    "\n",
    "As usual, classical music is far from the rest, with Jazz (and Blues) also differing from the rest somewhat.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e299cb-eed2-4335-bfde-225ed7c57e31",
   "metadata": {},
   "source": [
    "Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94d564-ead2-4155-bd01-d050672d9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaed1ba-d7f3-4044-a730-52917f8ecb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['mode'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fadaa9-ee0b-4b8c-99de-efa1262272d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x=\"music_genre\", hue=\"mode\",data=data)\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9d175-1597-464b-91a3-875408e110fb",
   "metadata": {},
   "source": [
    "\n",
    "All genres seem to have a prefererence for the \"Major\" mode, but to different degrees. It is the most pronounced in the Country genre. We'll use this feature after one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff60dc1-17b2-4a1b-958c-750790aea0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# One Hot Encoding\n",
    "data = pd.get_dummies(data, drop_first=True, columns=['mode'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ede866-cf54-44dc-93b3-4fa97e1fb0e8",
   "metadata": {},
   "source": [
    "Speechiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55086d9-5db0-4de7-875f-985081c4279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['speechiness'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc679298-ac95-4789-af91-809f9c397fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='speechiness')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acc15a-e610-415a-8be2-3001b542f014",
   "metadata": {},
   "source": [
    "\n",
    "This feature should contribute especially to identifying Hip-Hop and Rap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21ca86-d4dc-4621-b043-9284c7806095",
   "metadata": {},
   "source": [
    "Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86df20-3780-4289-b19f-15c5f42806fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['tempo'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2670b-be5c-4ee2-824a-392ee891c437",
   "metadata": {},
   "source": [
    "\n",
    "This feature should be numeric. The \"?\" is a missing value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e305b9-8489-4547-8016-61b1001751ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"This feature contains {(data[data['tempo'] == '?'].shape[0]/data.shape[0])*100:2.4}% missing values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8791d7f-0d76-43fa-8d09-fee62aa087c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# replace \"?\" with np.nan and correctly classify the feature:\n",
    "data.loc[data['tempo'] == '?', 'tempo'] = np.nan\n",
    "data = data.astype({'tempo': np.float64})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6693521-2c41-45cf-b6bc-6823f9a95baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['tempo'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea91098-7e63-4d6c-b238-cbe98ef5153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='tempo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7b962-6335-48ff-9aaf-5c44133d2629",
   "metadata": {},
   "source": [
    "\n",
    "The variation between genres is not great. We'll fill missing values with the median, but consider dropping the feature altogether in the future.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969eea9-d6ab-4360-bc4b-1f5b7efd3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "median_tempo = data['tempo'].median()\n",
    "data['tempo'] = data['tempo'].fillna(median_tempo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5ae16-3590-47b5-be6b-ef289bde1b98",
   "metadata": {},
   "source": [
    "\n",
    "Obtained date:¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06c1bf-5dfd-4746-a3d2-31ea4a152dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['obtained_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb431597-c6b4-4ed4-a7a9-08fa91299af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['obtained_date'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d650f0e-a9b2-4481-81e1-047036e0a0a4",
   "metadata": {},
   "source": [
    "\n",
    "Only gives the 4 dates at which the data was obtained. Not useful to us, so we'll drop it.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888dfbd-99d7-4c87-90c2-7fd660ea1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['obtained_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757037a7-16d1-47a7-8a1e-a2d3454e0e97",
   "metadata": {},
   "source": [
    "\n",
    "Valence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6691-808f-4c28-8db5-846cdeb1bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('music_genre')['valence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c803ae-7723-4d9f-a953-69f64a139799",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=data, x='music_genre', y='valence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d3a3e-b7d3-461f-ba4a-5473bf201690",
   "metadata": {},
   "source": [
    "\n",
    "Again, only classical music truly stands out from the rest.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfeb19d-e8af-47f6-ba42-e791b00df9c7",
   "metadata": {},
   "source": [
    "EDA Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eec8c-8528-4e13-a6b3-76304ef722f3",
   "metadata": {},
   "source": [
    "Labels:\n",
    "\n",
    "There are 10 equally likely musical genres (balanced dataset):\n",
    "\n",
    "    Alternative\n",
    "    Anime\n",
    "    Blues\n",
    "    Classical\n",
    "    Country\n",
    "    Electronic\n",
    "    Hip-Hop\n",
    "    Jazz\n",
    "    Rap\n",
    "    Rock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9e2ee-9a80-437d-b4c7-c5b8b4c01edf",
   "metadata": {},
   "source": [
    "Features:\n",
    "\n",
    "Useful features:\n",
    "\n",
    "    popularity - left as is.\n",
    "    acousticness - left as is.\n",
    "    danceability - left as is.\n",
    "    duration_ms - 10% of the entries had missing values, they were filled in with the median.\n",
    "    energy - left as is.\n",
    "    key - a categorical column containing 12 unique categories. One hot encoding was used.\n",
    "    liveness - left as is with a caveat: may be removed later on due to a lack of variance between genres.\n",
    "    loudness - left as is.\n",
    "    mode - a categorical column containing only 2 unique categories. One hot encoding was used.\n",
    "    speechiness - left as is.\n",
    "    tempo - contained 10% missing values and missclassified as catagorical. The missing values were filled in with the median and the feature was correctly classified as numerical. Caveat: contains very similar distributions between the genres. might be removed later on.\n",
    "    valence - left as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1ffcd-d02c-4236-bf5c-7762dcdba73a",
   "metadata": {},
   "source": [
    "Unhelpful Features that where removed:\n",
    "\n",
    "    instance_id - only an index.\n",
    "    obtained_date - only contains the 4 consecutive dates of data aquisition.\n",
    "    instrumentalness - contains 30% missing values.\n",
    "    artist_name and track_name - were used to obtain new features (see below) and then discarded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea7997-6945-433e-bb78-5552b39ea937",
   "metadata": {},
   "source": [
    "New features:\n",
    "\n",
    "    length_track_name - the track_name feature has essentially been converted to the length of the name. This feature helps identify the classic genre.\n",
    "    Japanese - This feature indicates wether the track/artist name is written in Japanese. This helps identify the Anime genre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999bc3a-0687-4a1b-9757-641464f035e7",
   "metadata": {},
   "source": [
    "General observations:\n",
    "\n",
    "It would appear that most genres tend to have very similar distributions in most features, making it hard for any model to distinguish between them. The obviouse exception is classical music, which has very different distributions in many features. The Anime genre also shows some distinguishing characteristics, as well as Jazz, to a much lesser extent. Hip-Hop and Rap are extremely similar to one another in all features, but are separate from the rest of the genres in some features. They might be easier to identify as one joint genre. All in all, The current features are unlikely to give great predictions for all genres. We'll find out if this is true soon enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c56855e-3863-42f5-b3fd-5a5b3024d4da",
   "metadata": {},
   "source": [
    "\n",
    "2. Final Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48253d2-f713-47e5-a454-00cfb63b1019",
   "metadata": {},
   "source": [
    "\n",
    "Separate features from labels and encode labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6143f-ef46-48f7-97dc-727778d89742",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['music_genre'] = data['music_genre'].astype('category')\n",
    "y = data['music_genre'].cat.codes\n",
    "y_names = list(data['music_genre'].cat.categories)\n",
    "\n",
    "X = data.drop(columns=['music_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b92262-9212-46e5-a64e-975afe1598d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34532805-d910-4213-8d12-15c72046e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d25f2-7752-41d9-b788-9b67651a22c1",
   "metadata": {},
   "source": [
    "\n",
    "Outlier Removal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca929d-836f-4cc5-8014-1a8d7063b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "numerical_feats = ['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "                   'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'length_track_name']\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=X_scaled[numerical_feats])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81bf8a1-9f23-4de2-b074-c6a65c0eaad4",
   "metadata": {},
   "source": [
    "As can be clearly seen, some features, especially the duration feature, contain extreme ouliers. These outliers can hinder the success of all models, so we'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae51db8-e068-4964-b725-94d9daa4511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_no_outliers = X_scaled[(np.abs(zscore(X_scaled[numerical_feats])) < 4).all(axis=1)]\n",
    "y_no_outliers = y[X_no_outliers.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecf832-8adb-4444-9d4a-2722dc91196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(data=X_no_outliers[numerical_feats])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848994ef-b1d0-4b2a-a410-b08aa63ce530",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(Note: Some of the features are clearly skewed. However, using log/boxcox on them did not improve the final results, and so it is ommitted here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15bf4a-b738-4a03-adad-280b8addfe10",
   "metadata": {},
   "source": [
    "Check correlation and reduce dimensionality with PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b7f6f-33da-4fe0-b5fe-b92dcf74b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(X_no_outliers.corr(), annot=False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1884e6-d133-492c-8679-2479e6976cee",
   "metadata": {},
   "source": [
    "\n",
    "Let's zoom in on the upper left corner where there are some noticeable correlations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6192d-271e-410e-8abe-73db111a7fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(X_no_outliers.iloc[:,:11].corr(), annot=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b79a3-5cb9-4f10-8fe9-72098d9d19da",
   "metadata": {},
   "source": [
    "\n",
    "Loudness, Acousticness and energy are highly correlated. PCA will address this while also reducing the dimesionality of our data set.¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f82087-3184-45d8-b59d-b0cf49f342af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_no_outliers)\n",
    "\n",
    "# find the first n components that account for 95% of the variance \n",
    "cum_exp_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = (cum_exp_var <= 0.95).sum()\n",
    "\n",
    "X_pca = pca.transform(X_no_outliers)[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e7b8b-b29a-4b18-a511-1078cbaf2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd8fa1-1d06-418c-b443-aba831e40359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_no_outliers, y_no_outliers, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bf181-70da-4357-97c7-a6a93eeb5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def get_metrics(model, X, y, y_names):\n",
    "    clf = model\n",
    "\n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the training set using cross-validation\n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"Mean CV score: {cv_scores.mean()*100:2.4}%\")\n",
    "\n",
    "    # Make predictions on the training and validation sets\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_valid = clf.predict(X_valid)\n",
    "\n",
    "    # Print accuracy scores and classification report for the validation set\n",
    "    print(f\"Train accuracy score: {accuracy_score(y_train, predict_train)*100:2.4}%\")\n",
    "    print(f\"Validation accuracy score: {accuracy_score(y_valid, predict_valid)*100:2.4}%\\n\")\n",
    "    print('Classification Report for the validation set:\\n')\n",
    "    print(classification_report(y_valid, predict_valid, target_names=y_names))\n",
    "    \n",
    "    # Plot the confusion matrix for the validation set\n",
    "    print('Confusion Matrix:\\n')\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(confusion_matrix(y_valid, predict_valid), annot = True, fmt = \".0f\", \n",
    "                cmap = \"coolwarm\", linewidths = 1, linecolor = \"white\",\n",
    "                xticklabels = y_names, yticklabels = y_names)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d1d6a-916b-4081-85a0-b67212b44013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_metrics_importance(model, X, y, y_names):\n",
    "    clf = model\n",
    "\n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances using permutation importance\n",
    "    result = permutation_importance(clf, X_train, y_train, n_repeats=10)\n",
    "    importances = result.importances_mean\n",
    "\n",
    "    # Get the feature names\n",
    "    feature_names = X.columns\n",
    "\n",
    "    # Plot feature importances on a pie graph\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.pie(importances, labels=feature_names, autopct='%1.1f%%')\n",
    "    ax.set_title('Feature Importances')\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model on the training and validation sets\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_valid = clf.predict(X_valid)\n",
    "\n",
    "    # Print accuracy scores and classification report for the validation set\n",
    "    print(f\"Train accuracy score: {accuracy_score(y_train, predict_train)*100:2.4}%\")\n",
    "    print(f\"Validation accuracy score: {accuracy_score(y_valid, predict_valid)*100:2.4}%\\n\")\n",
    "    print('Classification Report for the validation set:\\n')\n",
    "    print(classification_report(y_valid, predict_valid, target_names=y_names))\n",
    "    \n",
    "    # Plot the confusion matrix for the validation set\n",
    "    print('Confusion Matrix:\\n')\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(confusion_matrix(y_valid, predict_valid), annot = True, fmt = \".0f\", \n",
    "                cmap = \"coolwarm\", linewidths = 1, linecolor = \"white\",\n",
    "                xticklabels = y_names, yticklabels = y_names)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ffb7a-5a74-4617-9083-9597be94b9cc",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcb6c9-bae5-47e1-bba7-3c1cc3e376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(SVC(), x_train, y_train, y_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a11bc8-19b2-40ec-a3bf-4a9b71ffcf04",
   "metadata": {},
   "source": [
    "The precision score for each class represents the proportion of true positives among all predicted positives, while the recall score represents the proportion of true positives among all actual positives. The F1-score is the harmonic mean of precision and recall, and provides a balanced measure of the two metrics.\n",
    "\n",
    "From the report, we can see that the model achieved the highest precision, recall, and F1-score for the Classical music category, followed by Hip-Hop and Rap. The model performed relatively well on the other three categories (Anime, Jazz, Blues and Electronic, and Rock, Alternative and Country) with F1-scores ranging from 0.75 to 0.75.\n",
    "\n",
    "The overall accuracy of the model on the validation set was 0.77, indicating that the model correctly predicted the genre of the song in 77% of cases. The weighted average of the evaluation metrics was also 0.77, indicating that the model performed similarly well across all categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be55a8-81b5-4021-902d-866c3578b663",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5223500-ef19-4c53-a609-4ddb17060835",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(KNeighborsClassifier(), x_train, y_train, y_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a01d9-874b-40bf-a64d-14a4fec7ec8c",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b046e-df9e-49b7-ad95-0d21b269ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(RandomForestClassifier(n_estimators=100,\n",
    "    \n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,), x_train, y_train, y_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48729883-3720-4d03-9874-71d15985dc1a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Note the obviouse overfitting appearant in this case (and in KNN to a lesser degree).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c9e9c-d513-492b-8f2a-6596d78b6f2d",
   "metadata": {},
   "source": [
    "It would appear that all of the models we tried were almost equaly as ineffective (~40-50% accuracy), but SVC does better than the rest and avoids overfitting.\n",
    "Before we'll analyze further, we'll do a short sanity check and see if this is related to the use of PCA, outlier removal, or if it has to do with the features that we engineered/filled missing values in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c3470-67ca-466a-883b-95402c312891",
   "metadata": {},
   "source": [
    "Try with less fetures, without PCA, and keeping the outliers in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d23f1-3414-4c20-924b-b6e0ec0333c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_reduced = X_scaled.drop(['duration_ms', 'liveness', 'tempo', 'length_track_name', 'Japanese'], axis=1)\n",
    "x_train_check, x_test_check, y_train_check, y_test_check = train_test_split(X_reduced, y, test_size=0.3)\n",
    "\n",
    "get_metrics(SVC(), x_train_check, y_train_check, y_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652140f-7d15-461c-bb28-1090eb316a2b",
   "metadata": {},
   "source": [
    "This had no effect on the poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c7b48-044d-40ed-8ed6-ba7aabbe8381",
   "metadata": {},
   "source": [
    "Modeling Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a5b47-ca45-416a-b9b7-82d9b6a3f705",
   "metadata": {},
   "source": [
    "SVM, KNN, and Random Forest models were used on the data set, but all yielded bad results (40-50% accuracy). SVM was the best out of a bad bunch.\n",
    "\n",
    "Possible effects of outliers, dimensionality reduction and missing values were tested and discarded.\n",
    "\n",
    "The next section will analyze the results in more depth and propose a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685a5a0-ff92-4c82-9c7b-180ea69221cc",
   "metadata": {},
   "source": [
    "Consolidating classes\n",
    "\n",
    "An important thing to note is that as we hypothesized from the EDA, one genre, classical music, has much higher precision/recall scores than all the rest. This is also true to a lesser extent regarding the Anime genre.\n",
    "\n",
    "Meanwhile, Hip-Hop and Rap seem to be interchangeable and can't be distinguished from one another, but they are relatively well separated from the rest of the genres (as evidenced by the confusion matrix).\n",
    "\n",
    "Rock, Alternative and maybe Country also seem to have some similarity resulting in missclassification. Same goes for Blues and Jazz and maybe Electronic. These combinations are much more tentative, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ebbc46-96b7-4cb0-bcca-04528c4ad271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_metrics(model, X, y, feature_names):\n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Fit the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate predictions\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # Calculate and print the accuracy, precision, recall, and F1 scores\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 score: {f1:.2f}')\n",
    "\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Set negative importances to 0\n",
    "    importances = np.maximum(importances, 0)\n",
    "\n",
    "    # Plot feature importances on a pie graph\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.pie(importances, labels=feature_names, autopct='%1.1f%%')\n",
    "    ax.set_title('Feature Importances')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9203b-fc71-4893-9ef1-495298fbdf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15fea7-f27c-4199-811d-7a2b76c0b96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae40b3-ff5a-44d9-afa5-e0fe7bad466b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4471de8-3636-4b5d-bd26-e2fa91c3ccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd7dd7-0999-4d87-85ed-e3480c9a4366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
